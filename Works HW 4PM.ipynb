{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37be50b4-f799-4257-943b-9dc41171f674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 8K_Filings\\AAPL_8K_1_2025-02-25.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_2_2025-01-30.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_3_2025-01-03.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_4_2024-10-31.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_5_2024-09-10.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_6_2024-08-26.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_7_2024-08-23.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_8_2024-08-01.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_9_2024-05-03.txt\n",
      "Saved: 8K_Filings\\AAPL_8K_10_2024-05-02.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_1_2025-01-29.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_2_2025-01-22.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_3_2024-12-11.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_4_2024-12-03.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_5_2024-10-30.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_6_2024-08-21.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_7_2024-07-30.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_8_2024-04-25.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_9_2024-03-08.txt\n",
      "Saved: 8K_Filings\\MSFT_8K_10_2024-01-30.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_1_2025-02-06.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_2_2024-10-31.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_3_2024-08-01.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_4_2024-05-24.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_5_2024-05-14.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_6_2024-05-03.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_7_2024-04-30.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_8_2024-04-10.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_9_2024-02-01.txt\n",
      "Saved: 8K_Filings\\AMZN_8K_10_2023-11-01.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_1_2025-03-18.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_2_2025-02-04.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_3_2024-10-29.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_4_2024-10-17.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_5_2024-09-24.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_6_2024-08-05.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_7_2024-07-23.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_8_2024-06-26.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_9_2024-06-13.txt\n",
      "Saved: 8K_Filings\\GOOGL_8K_10_2024-06-07.txt\n",
      "Saved: 8K_Filings\\META_8K_1_2025-02-20.txt\n",
      "Saved: 8K_Filings\\META_8K_2_2025-01-29.txt\n",
      "Saved: 8K_Filings\\META_8K_3_2025-01-06.txt\n",
      "Saved: 8K_Filings\\META_8K_4_2024-10-30.txt\n",
      "Saved: 8K_Filings\\META_8K_5_2024-09-10.txt\n",
      "Saved: 8K_Filings\\META_8K_6_2024-08-09.txt\n",
      "Saved: 8K_Filings\\META_8K_7_2024-07-31.txt\n",
      "Saved: 8K_Filings\\META_8K_8_2024-05-31.txt\n",
      "Saved: 8K_Filings\\META_8K_9_2024-04-24.txt\n",
      "Saved: 8K_Filings\\META_8K_10_2024-02-14.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_1_2025-03-07.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_2_2025-02-26.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_3_2025-01-17.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_4_2024-11-20.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_5_2024-11-07.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_6_2024-08-28.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_7_2024-07-02.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_8_2024-06-07.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_9_2024-05-22.txt\n",
      "Saved: 8K_Filings\\NVDA_8K_10_2024-03-14.txt\n",
      "Saved: 8K_Filings\\JPM_8K_1_2025-02-04.txt\n",
      "Saved: 8K_Filings\\JPM_8K_2_2025-01-27.txt\n",
      "Saved: 8K_Filings\\JPM_8K_3_2025-01-24.txt\n",
      "Saved: 8K_Filings\\JPM_8K_4_2025-01-23.txt\n",
      "Saved: 8K_Filings\\JPM_8K_5_2025-01-15.txt\n",
      "Saved: 8K_Filings\\JPM_8K_6_2025-01-15.txt\n",
      "Saved: 8K_Filings\\JPM_8K_7_2025-01-14.txt\n",
      "Saved: 8K_Filings\\JPM_8K_8_2024-12-12.txt\n",
      "Saved: 8K_Filings\\JPM_8K_9_2024-11-29.txt\n",
      "Saved: 8K_Filings\\JPM_8K_10_2024-10-22.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_1_2025-01-29.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_2_2025-01-02.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_3_2024-10-23.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_4_2024-10-02.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_5_2024-07-23.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_6_2024-07-02.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_7_2024-06-14.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_8_2024-04-23.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_9_2024-04-16.txt\n",
      "Saved: 8K_Filings\\TSLA_8K_10_2024-04-02.txt\n",
      "Saved: 8K_Filings\\PFE_8K_1_2025-02-04.txt\n",
      "Saved: 8K_Filings\\PFE_8K_2_2024-12-17.txt\n",
      "Saved: 8K_Filings\\PFE_8K_3_2024-10-29.txt\n",
      "Saved: 8K_Filings\\PFE_8K_4_2024-10-15.txt\n",
      "Saved: 8K_Filings\\PFE_8K_5_2024-07-30.txt\n",
      "Saved: 8K_Filings\\PFE_8K_6_2024-07-26.txt\n",
      "Saved: 8K_Filings\\PFE_8K_7_2024-07-10.txt\n",
      "Saved: 8K_Filings\\PFE_8K_8_2024-07-01.txt\n",
      "Saved: 8K_Filings\\PFE_8K_9_2024-05-22.txt\n",
      "Saved: 8K_Filings\\PFE_8K_10_2024-05-01.txt\n",
      "Saved: 8K_Filings\\PEP_8K_1_2025-02-07.txt\n",
      "Saved: 8K_Filings\\PEP_8K_2_2025-02-07.txt\n",
      "Saved: 8K_Filings\\PEP_8K_3_2025-02-03.txt\n",
      "Saved: 8K_Filings\\PEP_8K_4_2024-12-11.txt\n",
      "Saved: 8K_Filings\\PEP_8K_5_2024-10-07.txt\n",
      "Saved: 8K_Filings\\PEP_8K_6_2024-09-20.txt\n",
      "Saved: 8K_Filings\\PEP_8K_7_2024-07-17.txt\n",
      "Saved: 8K_Filings\\PEP_8K_8_2024-07-10.txt\n",
      "Saved: 8K_Filings\\PEP_8K_9_2024-05-24.txt\n",
      "Saved: 8K_Filings\\PEP_8K_10_2024-05-03.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Your Name (your.email@example.com)\"\n",
    "}\n",
    "BASE_URL = \"https://www.sec.gov\"\n",
    "SAVE_DIR = \"8K_Filings\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def get_cik(ticker):\n",
    "    url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    data = response.json()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if value[\"ticker\"].lower() == ticker.lower():\n",
    "            return str(value[\"cik_str\"]).zfill(10)\n",
    "    return None\n",
    "\n",
    "def get_8k_filings(cik, count=3):\n",
    "    search_url = f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik}&type=8-K&count={count}&output=atom\"\n",
    "    response = requests.get(search_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"xml\")\n",
    "    entries = soup.find_all(\"entry\")\n",
    "    filings = []\n",
    "\n",
    "    for entry in entries:\n",
    "        filing_url = entry.find(\"filing-href\").text.replace(\"-index.htm\", \".txt\")\n",
    "        filing_time = entry.find(\"updated\").text\n",
    "        filings.append((filing_url, filing_time))\n",
    "\n",
    "    return filings\n",
    "\n",
    "def download_filing(filing_url, save_path):\n",
    "    response = requests.get(filing_url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Saved: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {filing_url}\")\n",
    "\n",
    "def main():\n",
    "    tickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"META\", \"NVDA\", \"JPM\", \"TSLA\", \"PFE\", \"PEP\"]\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        cik = get_cik(ticker)\n",
    "        if not cik:\n",
    "            print(f\"CIK not found for {ticker}\")\n",
    "            continue\n",
    "\n",
    "        filings = get_8k_filings(cik)\n",
    "        for i, (filing_url, filing_time) in enumerate(filings):\n",
    "            filename = f\"{ticker}_8K_{i+1}_{filing_time[:10]}.txt\"\n",
    "            save_path = os.path.join(SAVE_DIR, filename)\n",
    "            download_filing(filing_url, save_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1484fe7b-f312-4665-a589-09f9900031ae",
   "metadata": {},
   "source": [
    "Modify This part below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fd2efdb-4cb0-4ced-a63d-003b01419c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5f28c42-55c5-488b-9e7b-2bf36e4fe75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "INPUT_DIR = \"8K_Filings\"\n",
    "OUTPUT_CSV = \"8k_products.csv\"\n",
    "\n",
    "def extract_product_info(text):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in SEC filings. Analyze the following 8-K text and identify any new product announcements.\n",
    "\n",
    "Return ONLY JSON in this format:\n",
    "{{\n",
    "  \"new_product\": \"Product Name\",\n",
    "  \"product_description\": \"Brief explanation of the product\"\n",
    "}}\n",
    "\n",
    "If no new product is mentioned, return:\n",
    "{{\n",
    "  \"new_product\": null,\n",
    "  \"product_description\": null\n",
    "}}\n",
    "\n",
    "Here is the 8-K text:\n",
    "{text[:4000]}  <!-- limit to 4k chars for token safety -->\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split(\"_\")\n",
    "    stock = parts[0]\n",
    "    date = parts[-1].replace(\".txt\", \"\")\n",
    "    return stock, date\n",
    "\n",
    "def process_all_filings():\n",
    "    results = []\n",
    "\n",
    "    for file in os.listdir(INPUT_DIR):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(INPUT_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            stock, filing_date = parse_filename(file)\n",
    "            json_text = extract_product_info(text)\n",
    "\n",
    "            try:\n",
    "                response_json = json.loads(json_text)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"⚠️ JSON decoding failed for file: {file}\")\n",
    "                continue\n",
    "            \n",
    "            results.append({\n",
    "                \"company_name\": stock,\n",
    "                \"stock_name\": stock,\n",
    "                \"filing_time\": filing_date,\n",
    "                \"new_product\": response_json[\"new_product\"],\n",
    "                \"product_description\": response_json[\"product_description\"]\n",
    "            })\n",
    "\n",
    "    with open(OUTPUT_CSV, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"company_name\", \"stock_name\", \"filing_time\", \"new_product\", \"product_description\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in results:\n",
    "            writer.writerow(row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_filings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f829f0a-5bd8-4aa5-a777-ce0b94a94ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e9309-e4bc-48fa-ac25-e98f125f748f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae29e9a-ec1c-4a76-91ea-5283b4e40d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c04b6-3b39-49c1-8980-9883ad8511d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909224d-89ce-49b5-bbf3-fdeb3e3dd528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd27dc-38fb-4355-8671-4812aebdb03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea7c4f-bedc-4cdc-b035-fb70d821b3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347b935-c539-4755-821a-3d5cb21aa803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fd5d3-9be5-4df9-8061-d672c333a193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88bda2-bca1-422d-8292-a48f28700d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed51993-5ef1-4bdb-a82e-22d7b1af833c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277de44b-c566-4ee3-bcea-13b010f7d6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62de723-0bd0-4b4c-87bf-80e172055001",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\"User-Agent\": \"Rafael Trotter ra494491@ucf.edu\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b39cdbf5-3dcb-48b5-ae26-fd70264a0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEC EDGAR base URL\n",
    "BASE_URL = \"https://www.sec.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bea462f9-1fc1-4b9e-b111-16c993aabcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to store filings\n",
    "SAVE_DIR = \"8K_Filings\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bcbf6e6-199c-432a-99ab-917b520eff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cik(ticker):\n",
    "    ticker = ticker.lower()\n",
    "    url = f\"https://www.sec.gov/files/company_tickers.json\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f3c7adb-3f76-4bee-96de-c7d02452cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cik_by_ticker(data, ticker):\n",
    "    for key, value in data.items():\n",
    "        if value[\"ticker\"].lower() == ticker.lower():\n",
    "            return str(value[\"cik_str\"]).zfill(10)  # Format as 10-digit CIK\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ffb64df-8919-44ab-864e-4a1017e44323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_8k_filings(cik, count=5):\n",
    "    \"\"\"Fetch the most recent 8-K filings for a given company CIK.\"\"\"\n",
    "    search_url = f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik}&type=8-K&count={count}&output=atom\"\n",
    "    response = requests.get(search_url, headers=HEADERS)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching filings.\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"xml\")\n",
    "    entries = soup.find_all(\"entry\")\n",
    "    filings = []\n",
    "\n",
    "    for entry in entries:\n",
    "        filing_url = entry.find(\"filing-href\").text.replace(\"-index.htm\", \".txt\")\n",
    "        filings.append(filing_url)\n",
    "\n",
    "    return filings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "153c8692-28bc-4946-88ba-64a92f073116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_filing(filing_url, save_path):\n",
    "    \"\"\"Download and save an 8-K filing.\"\"\"\n",
    "    response = requests.get(filing_url, headers=HEADERS)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Saved: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {filing_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27e24931-f890-45b7-9c40-1f39eed8409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter stock ticker (e.g., AAPL):  AAPL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid ticker or CIK not found.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ticker = input(\"Enter stock ticker (e.g., AAPL): \").strip().upper()\n",
    "    cik = get_cik(ticker)\n",
    "\n",
    "    if not cik:\n",
    "        print(\"Invalid ticker or CIK not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Fetching 8-K filings for CIK: {cik}\")\n",
    "    filings = get_8k_filings(cik)\n",
    "\n",
    "    if not filings:\n",
    "        print(\"No recent 8-K filings found.\")\n",
    "        return\n",
    "\n",
    "    for idx, filing_url in enumerate(filings):\n",
    "        save_path = os.path.join(SAVE_DIR, f\"{ticker}_8K_{idx+1}.txt\")\n",
    "        download_filing(filing_url, save_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634166c-f156-4dd9-b766-a3b7a7f0814a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
